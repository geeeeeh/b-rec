import streamlit as st
import json, re, datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“š êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ")
st.caption("JSON ì—…ë¡œë“œ â†’ ì±… ì„ íƒ ë˜ëŠ” í‚¤ì›Œë“œ ì…ë ¥ â†’ ìœ ì‚¬ë„ + ìµœê·¼ 5ë…„ ê°€ì¤‘ì¹˜ë¡œ ì¶”ì²œ")

# ---------------------------
# 1) JSON ì•ˆì „ ë¡œë”
# ---------------------------
def safe_load_json(file):
    """
    - UTF-8 BOM ì œê±°
    - ì—¬ëŸ¬ JSONì´ ë¶™ì–´ ìˆëŠ” íŒŒì¼ì—ì„œë„ 'ì²« ë²ˆì§¸ JSON ê°ì²´'ë§Œ íŒŒì‹±
    """
    text = file.read().decode("utf-8-sig")
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        try:
            decoder = json.JSONDecoder()
            obj, _ = decoder.raw_decode(text.lstrip())
            return obj
        except Exception as e:
            st.error(f"âŒ JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {e}")
            return None

# ---------------------------
# 2) ì•ˆì „ ë¬¸ìì—´ ë³€í™˜ ìœ í‹¸
# ---------------------------
def to_text(v):
    """ê°’ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜: list/dict/None/ìˆ«ì ì „ë¶€ OK"""
    if v is None:
        return ""
    if isinstance(v, str):
        return v
    if isinstance(v, (int, float, bool)):
        return str(v)
    if isinstance(v, list):
        return " ".join(to_text(x) for x in v)
    if isinstance(v, dict):
        return " ".join(to_text(x) for x in v.values())
    return str(v)

# ---------------------------
# 3) ì¶œíŒë…„ë„ ì¶”ì¶œ & ìµœê·¼ 5ë…„ ê°€ì¤‘ì¹˜
# ---------------------------
YEAR_RE = re.compile(r"(19|20)\d{2}")

def extract_year(book):
    """
    issuedYear, issued, datePublished ë“±ì—ì„œ 4ìë¦¬ ì—°ë„ ì¶”ì¶œ.
    ì˜ˆ) 'æ°‘åœ‹77[1988]' â†’ 1988, '2022-11-10...' â†’ 2022
    """
    cand = [
        to_text(book.get("issuedYear")),
        to_text(book.get("issued")),
        to_text(book.get("datePublished")),
        to_text(book.get("publicationDate")),
    ]
    for c in cand:
        m = YEAR_RE.search(c)
        if m:
            try:
                return int(m.group(0))
            except:
                pass
    return None

def recency_weight(year, now_year=None):
    """
    ìµœê·¼ 5ë…„ ì„ í˜• ê°€ì¤‘ì¹˜.
    ì˜¬í•´=1.0, 1ë…„ ì „=0.8, â€¦, 5ë…„ ì´ìƒ ì§€ë‚œ ì±…=0
    """
    if year is None:
        return 0.0
    if now_year is None:
        now_year = datetime.date.today().year
    d = now_year - year
    if d < 0:
        d = 0
    if d <= 5:
        return (5 - d) / 5.0
    return 0.0

# ---------------------------
# 4) ì½”í¼ìŠ¤/íƒ€ì´í‹€/ë©”íƒ€ ìƒì„±
# ---------------------------
def build_corpus(data):
    if not isinstance(data, dict):
        return [], [], [], []
    books = data.get("@graph", [])
    if not isinstance(books, list) or not books:
        return [], [], [], []

    corpus, titles, years, raw = [], [], [], []
    for bk in books:
        parts = [
            to_text(bk.get("title")),
            to_text(bk.get("remainderOfTitle")),
            to_text(bk.get("creator")),
            to_text(bk.get("dcterms:creator")),
            to_text(bk.get("subject")),
            to_text(bk.get("description")),
            to_text(bk.get("titleOfSeries")),
            to_text(bk.get("publisher")),
            to_text(bk.get("kdc")),
            to_text(bk.get("publicationPlace")),
        ]
        text = " ".join(p for p in parts if p)
        corpus.append(text)
        titles.append(to_text(bk.get("title")) or "(ì œëª© ì—†ìŒ)")
        years.append(extract_year(bk))
        raw.append(bk)
    return corpus, titles, years, raw

# ---------------------------
# ì•± ë³¸ë¬¸
# ---------------------------
uploaded = st.file_uploader("ë„ì„œì •ë³´ JSON íŒŒì¼ ì—…ë¡œë“œ", type=["json"])
if not uploaded:
    st.info("ğŸ“‚ ë¨¼ì € JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

data = safe_load_json(uploaded)
if data is None:
    st.stop()

corpus, titles, years, raw_books = build_corpus(data)
if not corpus:
    st.warning("âš ï¸ '@graph' ë‚´ ë„ì„œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# TF-IDF ì „ì—­ í•™ìŠµ (ì±… ì„ íƒí˜• & í‚¤ì›Œë“œí˜•ì— ê³µí†µ ì‚¬ìš©)
vectorizer = TfidfVectorizer()
tfidf = vectorizer.fit_transform(corpus)

# ì‚¬ì´ë“œë°”: ê°€ì¤‘ì¹˜ ì„¤ì •
st.sidebar.header("âš–ï¸ ê°€ì¤‘ì¹˜ ì„¤ì •")
w_recency = st.sidebar.slider("ìµœê·¼ 5ë…„ ê°€ì¤‘ì¹˜ ë¹„ìœ¨", min_value=0.0, max_value=0.8, value=0.3, step=0.05,
                              help="ìµœì¢… ì ìˆ˜ = (1-ë¹„ìœ¨)*ë‚´ìš©ìœ ì‚¬ë„ + (ë¹„ìœ¨)*ìµœê·¼ì„±")
top_n = st.sidebar.slider("ì¶”ì²œ ê°œìˆ˜ (Top N)", 3, 15, 5)

now_year = datetime.date.today().year
recency_vec = [recency_weight(y, now_year) for y in years]

def rerank_with_recency(sim_scores):
    # sim_scores: numpy array
    # recency_vec: íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ â†’ ê°™ì€ ê¸¸ì´ ë³´ì¥
    import numpy as np
    rec = np.array(recency_vec, dtype=float)
    return (1 - w_recency) * sim_scores + (w_recency) * rec

col1, col2 = st.columns(2, vertical_alignment="top")

# ---------------------------
# A) ì±… ì„ íƒí˜• ì¶”ì²œ
# ---------------------------
with col1:
    st.subheader("ğŸ” ì±… ì„ íƒí˜• ì¶”ì²œ")
    sel_title = st.selectbox("ì¶”ì²œ ê¸°ì¤€ì´ ë  ì±…ì„ ì„ íƒí•˜ì„¸ìš”", options=titles)
    if st.button("ì´ ì±…ê³¼ ë¹„ìŠ·í•œ ë„ì„œ ì¶”ì²œ", use_container_width=True):
        try:
            idx = titles.index(sel_title)
        except ValueError:
            st.error("ì„ íƒí•œ ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        sims = cosine_similarity(tfidf[idx], tfidf).flatten()
        final = rerank_with_recency(sims)

        order = final.argsort()[::-1]
        recs = [i for i in order if i != idx][:top_n]

        st.write(f"**ê¸°ì¤€ ë„ì„œ:** {sel_title}")
        for i in recs:
            creator = to_text(raw_books[i].get("creator")) or "ì €ì ì •ë³´ ì—†ìŒ"
            kdc = to_text(raw_books[i].get("kdc")) or "N/A"
            y = years[i] or "N/A"
            st.markdown(
                f"- **{titles[i]}** â€” {creator} (KDC: {kdc}, ì—°ë„: {y})  "
                f"Â· ë‚´ìš©ìœ ì‚¬ë„: {cosine_similarity(tfidf[idx], tfidf[i]).flatten()[0]:.3f}  "
            )

# ---------------------------
# B) í‚¤ì›Œë“œ ê²€ìƒ‰í˜• ì¶”ì²œ
# ---------------------------
with col2:
    st.subheader("ğŸ“ í‚¤ì›Œë“œ ê²€ìƒ‰í˜• ì¶”ì²œ")
    q = st.text_input("ê´€ì‹¬ í‚¤ì›Œë“œ/ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë„ì„œê´€í•™, ì €ì‘ê¶Œë²•, ì—­ì‚¬)")
    if st.button("í‚¤ì›Œë“œë¡œ ì¶”ì²œ", use_container_width=True):
        if not q.strip():
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            q_vec = vectorizer.transform([q.strip()])
            sims = cosine_similarity(q_vec, tfidf).flatten()
            final = rerank_with_recency(sims)

            order = final.argsort()[::-1][:top_n]
            st.write(f"**ì…ë ¥ í‚¤ì›Œë“œ:** {q}")
            for i in order:
                creator = to_text(raw_books[i].get("creator")) or "ì €ì ì •ë³´ ì—†ìŒ"
                kdc = to_text(raw_books[i].get("kdc")) or "N/A"
                y = years[i] or "N/A"
                st.markdown(
                    f"- **{titles[i]}** â€” {creator} (KDC: {kdc}, ì—°ë„: {y})  "
                    f"Â· ë‚´ìš©ìœ ì‚¬ë„: {cosine_similarity(q_vec, tfidf[i]).flatten()[0]:.3f}"
                )
